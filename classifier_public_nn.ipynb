{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffe6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import sklearn\n",
    "import pathlib\n",
    "import os\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6fb5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "positive_directory = Path('data/Positive')\n",
    "negative_directory = Path('data/Negative')\n",
    "uncertain_directory = Path('data/Uncertain')\n",
    "\n",
    "positive_labels_file = \"data/Positive/Positive.xlsx\"\n",
    "negative_labels_file = \"data/Negative/Negative.xlsx\"\n",
    "uncertain_labels_file = \"data/Uncertain/Uncertain.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dc9160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'A': 'Positive', 'B': 'Positive', 'C': 'Negative', 'D': 'Uncertain', 'E': 'Uncertain'}\n",
    "label_to_idx = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbf8b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1500 images into tensors\n",
      "X shape: torch.Size([1500, 3, 224, 224]), y shape: torch.Size([1500])\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    (positive_labels_file, positive_directory),\n",
    "    (negative_labels_file, negative_directory),\n",
    "    (uncertain_labels_file, uncertain_directory),\n",
    "]\n",
    "\n",
    "total_images = 0\n",
    "for labels_file, directory in datasets:\n",
    "    total_images += len(list(directory.glob('*.jpg')))\n",
    "\n",
    "img_height, img_width = 224, 224\n",
    "X_tensor = torch.empty((total_images, 3, img_height, img_width), dtype=torch.float32)\n",
    "y_tensor = torch.empty(total_images, dtype=torch.long)\n",
    "\n",
    "idx = 0\n",
    "for labels_file, directory in datasets:\n",
    "    labels_df = pd.read_excel(labels_file)\n",
    "    label_dict = dict(zip(labels_df['fileName'], labels_df['Label'])) \n",
    "    \n",
    "    for file in directory.glob('*.jpg'):\n",
    "        if file.is_file():\n",
    "            #print(f\"Processing file: {file.name}\")\n",
    "            img = cv2.imread(str(file))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "            img = cv2.resize(img, (img_width, img_height))  \n",
    "            \n",
    "            img_tensor = torch.from_numpy(img).float() / 255.0  \n",
    "            img_tensor = img_tensor.permute(2, 0, 1)  \n",
    "            \n",
    "            X_tensor[idx] = img_tensor\n",
    "            label_letter = label_dict.get(file.name, 'E')  \n",
    "            y_tensor[idx] = label_to_idx[label_letter]\n",
    "            \n",
    "            idx += 1\n",
    "            #print(idx, file.name, label_letter, y_tensor[idx-1].item())\n",
    "\n",
    "print(f\"Loaded {idx} images into tensors\")\n",
    "print(f\"X shape: {X_tensor.shape}, y shape: {y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d96457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04baddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb1e64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d4e0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c217f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1c62a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))    # [B, 16, 112, 112]\n",
    "        x = self.pool(F.relu(self.conv2(x)))    # [B, 32, 56, 56]\n",
    "        x = x.view(x.size(0), -1)               # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99a30207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1200, 3, 224, 224]),\n",
       " torch.Size([1200]),\n",
       " torch.Size([300, 3, 224, 224]),\n",
       " torch.Size([300]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size(), y_train.size(), X_test.size(), y_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58b7a945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 61.2381\n",
      "Epoch [2/10], Loss: 39.1642\n",
      "Epoch [3/10], Loss: 31.8685\n",
      "Epoch [4/10], Loss: 29.0210\n",
      "Epoch [5/10], Loss: 27.2691\n",
      "Epoch [6/10], Loss: 24.2538\n",
      "Epoch [7/10], Loss: 22.5591\n",
      "Epoch [8/10], Loss: 21.0327\n",
      "Epoch [9/10], Loss: 19.1636\n",
      "Epoch [10/10], Loss: 17.2415\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "num_classes = 5\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Model setup\n",
    "model = BasicCNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {running_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4807dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, X_test, y_test, batch_size=32):\n",
    "    model.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)  \n",
    "            _, predicted = torch.max(outputs, 1)  \n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82c73623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 70.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70.66666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a74d4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 224, 224  # Set your target dimensions\n",
    "\n",
    "def test_from_image(filepath):\n",
    "    img = cv2.imread(str(file))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = cv2.resize(img, (img_width, img_height))  # Resize\n",
    "            \n",
    "    # Convert directly to tensor\n",
    "    img_tensor = torch.from_numpy(img).float() / 255.0  # Normalize to [0,1]\n",
    "    img_tensor = img_tensor.permute(2, 0, 1)  # Change HWC to CHW\n",
    "\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)  # Forward pass\n",
    "        _, predicted = torch.max(output, 1)  # Get predicted class index\n",
    "    \n",
    "    #print filename and predicted label\n",
    "    print(f\"File: {filepath}, Predicted Label Index: {predicted.item()}, Predicted Label: {list(label_to_idx.keys())[predicted.item()]}\")\n",
    "    return list(label_to_idx.keys())[predicted.item()]\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
